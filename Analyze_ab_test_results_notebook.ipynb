{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze A/B Test Results\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "- [Introduction](#intro)\n",
    "- [Part I - Probability](#probability)\n",
    "- [Part II - A/B Test](#ab_test)\n",
    "- [Part III - Regression](#regression)\n",
    "\n",
    "\n",
    "<a id='intro'></a>\n",
    "### Introduction\n",
    "\n",
    "A/B tests are very commonly performed by data analysts and data scientists.  It is important that you get some practice working with the difficulties of these \n",
    "\n",
    "For this project, you will be working to understand the results of an A/B test run by an e-commerce website.  Your goal is to work through this notebook to help the company understand if they should implement the new page, keep the old page, or perhaps run the experiment longer to make their decision.\n",
    "\n",
    "\n",
    "<a id='probability'></a>\n",
    "#### Part I - Probability\n",
    "\n",
    "To get started, let's import our libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#We are setting the seed to assure you get the same answers on quizzes as we set up\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1.` Now, we will read in the `ab_data.csv` data, and store it in `df`. \n",
    "\n",
    "a. Read in the dataset and take a look at the top few rows here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0\n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0\n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0\n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0\n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ab_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Number of rows in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294478"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. The number of unique users in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "d. The proportion of users converted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12104245244060237"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.query('converted == 1').groupby('user_id'))/290584"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "e. The number of times the `new_page` and `treatment` don't match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id         3893\n",
       "timestamp       3893\n",
       "group           3893\n",
       "landing_page    3893\n",
       "converted       3893\n",
       "dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query('group == \"treatment\" & landing_page == \"old_page\"').count() + \\\n",
    "df.query('group == \"control\" & landing_page == \"new_page\"').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Checking for missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id         0\n",
       "timestamp       0\n",
       "group           0\n",
       "landing_page    0\n",
       "converted       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` For the rows where **treatment** does not match with **new_page** or **control** does not match with **old_page**, we cannot be sure if this row truly received the new or old page. \n",
    "\n",
    "a. We will create a new dataset that excludes these rows and store the new dataframe in **df2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlt = df.query('group == \"treatment\" & landing_page == \"old_page\"').index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlt = np.append(dlt, df.query('group == \"control\" & landing_page == \"new_page\"').index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.drop(dlt, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double Check all of the correct rows were removed - this should be 0\n",
    "df2[((df2['group'] == 'treatment') == (df2['landing_page'] == 'new_page')) == False].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Unique **user_id**s in **df2**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "b. Duplicated **user_ids**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2893    773192\n",
       "Name: user_id, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2['user_id'].duplicated() == True].user_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. The row information for the duplicated **user_id**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-14 02:55:59.590927</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "2893   773192  2017-01-14 02:55:59.590927  treatment     new_page          0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2['user_id'].duplicated() == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. We will remove **one** of the rows with a duplicate **user_id**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop(2893, 0, inplace=True)\n",
    "#2893 is the index we got from the info above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.`\n",
    "\n",
    "a. The probability of an individual converting regardless of the page they receive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.query('converted == 1').shape[0]/290584"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. The probability that an individual converted given that they were in the `control` group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we get the number of total individuals in the control group\n",
    "nOcontrol = df2.query('group == \"control\"').shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1203863045004612"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we divide the number of those converted from the group over the total\n",
    "df2.query('converted == 1 & group == \"control\"').shape[0]/nOcontrol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. The probability that an individual converted Given that they were in the `treatment` group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we get the total of the individuals in the treatment group\n",
    "nOtreatment = df2.query('group == \"treatment\"').shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11880806551510564"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we divide the number of those converted from the group over the total\n",
    "df2.query('converted == 1 & group == \"treatment\"').shape[0]/nOtreatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. The probability that an individual received the new page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000619442226688"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.query('landing_page == \"new_page\"').shape[0]/df2.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e. There is no sufficient evidence to conclude that the new treatment page leads to more conversions. The probability of an individual in the treatment group converting is 5.9% wherein it's 6% for individuals in the control group. The difference between the two is too small to make such conclusions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ab_test'></a>\n",
    "### Part II - A/B Test\n",
    "\n",
    "\n",
    "`1.` Assuming that the old page is better unless the new page proves to be definitely better at a Type I error rate of 5%:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$H_{0}$** = **$p_{new}$** - **$p_{old}$** <= 0\n",
    "\n",
    "**$H_{1}$** = **$p_{new}$** - **$p_{old}$** > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$p_{old}$** and **$p_{new}$**: the converted rates for the old and new pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Assuming under the null hypothesis, $p_{new}$ and $p_{old}$ both have \"true\" success rates equal to the **converted** success rate regardless of page - that is $p_{new}$ and $p_{old}$ are equal. Furthermore, assuming they are equal to the **converted** rate in **ab_data.csv** regardless of the page. <br><br>\n",
    "\n",
    "First, we will use a sample size for each page equal to the ones in **ab_data.csv:** <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. The **conversion rate** for $p_{new}$ under the null:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pnew = df2['converted'].mean()\n",
    "pnew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. The **conversion rate** for $p_{old}$ under the null: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pold = df2['converted'].mean()\n",
    "pold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. $n_{new}$, the number of individuals in the treatment group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145310"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnew = df2.query('group == \"treatment\"').shape[0]\n",
    "nnew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. $n_{old}$, the number of individuals in the control group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145274"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nold = len(df2.query('group == \"control\"'))\n",
    "nold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. We will simulate $n_{new}$ transactions with a conversion rate of $p_{new}$ under the null, and store these $n_{new}$ 1's and 0's in **new_page_converted**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_page_converted = np.random.choice([0, 1], size = nnew, p = [pnew, 1 - pnew])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Now we will simulate $n_{old}$ transactions with a conversion rate of $p_{old}$ under the null and store these $n_{old}$ 1's and 0's in **old_page_converted**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_page_converted = np.random.choice([0, 1], size = nold, p = [pold, 1 - pold])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g. $p_{new}$ - $p_{old}$ for our simulated values from part (e) and (f):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0032302861824287099"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_page_converted.mean() - old_page_converted.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h. Now, we will perform the sampling distribution for the difference in **converted** between the two pages over 10,000 iterations of calculating an estimate from the null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will create 10,000 pnew - pold values and store them in p_diffs array\n",
    "p_diffs = []\n",
    "\n",
    "for i in range(10000):\n",
    "    new_page_converted = np.random.choice([0, 1], size = nnew, p = [pnew, 1 - pnew])\n",
    "    old_page_converted = np.random.choice([0, 1], size = nold, p = [pold, 1 - pold])\n",
    "    p_diffs.append(new_page_converted.mean() - old_page_converted.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. A histogram of the **p_diffs**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1327cf8358>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(p_diffs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "j. Now we want to find the proportion of the **p_diffs** greater than the actual difference observed in **ab_data.csv**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will find the actual difference observed in **ab_data.csv**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment = df2.query('group == \"treatment\"')['converted'].mean()\n",
    "control = df2.query('group == \"control\"')['converted'].mean()\n",
    "act_diffs = treatment - control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the proportion of the p_diffs greater than the actual difference in **ab_data.csv:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90620000000000001"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_diffs = np.array(p_diffs)\n",
    "(p_diffs > act_diffs).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**k. What we just computed is a term referred to as the probability value or pvalue. Pvalue is the probability of obtaining test results at least as extreme as the results actually observed, assuming that the null hypothesis is correct. Having a large pvalue indicates weak evidence against the null hypothesis, so we fail to reject it.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l. We could also use a built-in to achieve similar results. We will let `n_old` and `n_new` refer to the number of rows associated with the old page and new pages, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "convert_old = df2.query('group == \"control\"').converted.sum()\n",
    "convert_new = df2.query('group == \"treatment\"').converted.sum()\n",
    "n_old = df2.query('group == \"control\"').shape[0]\n",
    "n_new = df2.query('group == \"treatment\"').shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m. Now we will use `stats.proportions_ztest` to compute our test statistic and p-value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.31092419842 0.905058312759\n"
     ]
    }
   ],
   "source": [
    "zscore, pvalue = sm.stats.proportions_ztest([convert_old, convert_new], [n_old, n_new], alternative='smaller')\n",
    "print(zscore, pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n. Now we want to find What the z-score and p-value we computed mean for the conversion rates of the old and new pages. Do they agree with the findings in parts **j.** and **k.**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90505831275902449"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first we need to compute the significance of our z-score:\n",
    "\n",
    "from scipy.stats import norm\n",
    "norm.cdf(zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6448536269514722"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#second, we compute our critical value at 95% confidence:\n",
    "\n",
    "norm.ppf(1-(0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since 1.31 < 1.64 this disapproves our alternative hypothesis. Concluding that the conversion rate for the new page is not more than the old page. Also, the pvalue computed is almost equal to the one computed in part j and k. Therefore, we agree with our previous findings and fail to reject the null hypothesis.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='regression'></a>\n",
    "### Part III - A regression approach\n",
    "\n",
    "`1.` In this final part, we will see that the result we achieved in the A/B test in Part II above can also be achieved by performing regression.<br><br> \n",
    "\n",
    "a. Since each row is either a conversion or no conversion, we will be performing **Logistic Regression**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. We will use **statsmodels** to fit the regression model we specified in part **a.** to see if there is a significant difference in conversion based on which page a customer receives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the intercept column\n",
    "df2['intercept'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   intercept  ab_page  \n",
       "0          1        0  \n",
       "1          1        0  \n",
       "2          1        1  \n",
       "3          1        1  \n",
       "4          1        0  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need the 1's to refer to treatment, and 0's to control, so we will\n",
    "# drop the dummy column since it will generate the opposite, and we'll\n",
    "# use the ab_page:\n",
    "df2[['dummy','ab_page']] = pd.get_dummies(df2['group'])\n",
    "df2.drop('dummy', axis=1, inplace=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. We will use **statsmodels** to instantiate our regression model on the two columns we created in part **b.**, then fit the model using them to predict whether or not an individual converts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = sm.Logit(df2['converted'],df2[['intercept' ,'ab_page']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Now we will provide the summary of our model below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366118\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290582</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     1</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Thu, 25 Jun 2020</td> <th>  Pseudo R-squ.:     </th>  <td>8.077e-06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>13:44:14</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>   <td>0.1899</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9888</td> <td>    0.008</td> <td> -246.669</td> <td> 0.000</td> <td>   -2.005</td> <td>   -1.973</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>   -0.0150</td> <td>    0.011</td> <td>   -1.311</td> <td> 0.190</td> <td>   -0.037</td> <td>    0.007</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290582\n",
       "Method:                           MLE   Df Model:                            1\n",
       "Date:                Thu, 25 Jun 2020   Pseudo R-squ.:               8.077e-06\n",
       "Time:                        13:44:14   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "                                        LLR p-value:                    0.1899\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9888      0.008   -246.669      0.000      -2.005      -1.973\n",
       "ab_page       -0.0150      0.011     -1.311      0.190      -0.037       0.007\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A workaround for an error\n",
    "from scipy import stats\n",
    "stats.chisqprob = lambda chisq, df2: stats.chi2.sf(chisq, df2)\n",
    "## \n",
    "\n",
    "## Summary of model\n",
    "result = logit.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e. The pvalue computed just now is 0.19 which is way less than the one computed in part II, which was 0.9. The reason for that is because the null and alternative hypotheses in this part are different from the previous ones. The test in Part II was one-sided, whereas this one is two-sided**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f. It will be good to explore whether other factors have higher influence, since it may also help with defining outliers. However, a disadvantage that may occur is inaccurate results due to correlation errors. Considering all influencing factors is not easy to execute, and focusing on smaller comparisons may yield better results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g. Now along with testing if the conversion rate changes for different pages, we will also add an effect based on which country a user lives in.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>834778</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>928468</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>822059</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>711597</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>710616</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id country\n",
       "0   834778      UK\n",
       "1   928468      US\n",
       "2   822059      UK\n",
       "3   711597      UK\n",
       "4   710616      UK"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will read the data from the countries file then join it with our df2\n",
    "countries_data = pd.read_csv('./countries.csv')\n",
    "countries_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.join(countries_data.set_index('user_id'), on = 'user_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h. We would now like to look at an interaction between page and country to see if there are significant effects on conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[['UK','US']] = pd.get_dummies(df2['country'])[['UK','US']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366116\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290581</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     2</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Thu, 25 Jun 2020</td> <th>  Pseudo R-squ.:     </th>  <td>1.521e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>13:44:15</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>   <td>0.1984</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -2.0375</td> <td>    0.026</td> <td>  -78.364</td> <td> 0.000</td> <td>   -2.088</td> <td>   -1.987</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>        <td>    0.0507</td> <td>    0.028</td> <td>    1.786</td> <td> 0.074</td> <td>   -0.005</td> <td>    0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>US</th>        <td>    0.0408</td> <td>    0.027</td> <td>    1.518</td> <td> 0.129</td> <td>   -0.012</td> <td>    0.093</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290581\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Thu, 25 Jun 2020   Pseudo R-squ.:               1.521e-05\n",
       "Time:                        13:44:15   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "                                        LLR p-value:                    0.1984\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -2.0375      0.026    -78.364      0.000      -2.088      -1.987\n",
       "UK             0.0507      0.028      1.786      0.074      -0.005       0.106\n",
       "US             0.0408      0.027      1.518      0.129      -0.012       0.093\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = sm.Logit(df2['converted'], df2[['intercept', 'UK', 'US']])\n",
    "\n",
    "results = logit.fit()\n",
    "\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The statistical evidence does not allow us to conclude that there is an impact since all the pvalues are more than 0.05. So, once again we cannot reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusions'></a>\n",
    "## Finishing Up\n",
    "\n",
    "> Congratulations!  You have reached the end of the A/B Test Results project!  You should be very proud of all you have accomplished!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "### https://docs.w3cub.com/statsmodels/generated/statsmodels.stats.proportion.proportions_ztest/\n",
    "### https://github.com/abodacs/Analyze-AB-Test-Results/blob/master/Analyze_ab_test_results_notebook.ipynb\n",
    "### https://github.com/khaledimad/Analyze-A-B-Test-Results/blob/master/Analyze_ab_test_results_notebook.ipynb\n",
    "### https://github.com/statsmodels/statsmodels/issues/3931"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'Analyze_ab_test_results_notebook.ipynb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
